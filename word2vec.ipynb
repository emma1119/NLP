{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ca3b6b24",
   "metadata": {},
   "source": [
    "Word2Vec is a specific algorithm for learning vector representations of words, which are known as word embeddings. The algorithm uses a shallow neural network to train on large amounts of text data and produce a vector for each word in a vocabulary, where the vectors are optimized to capture the relationships between words in the data.\n",
    "\n",
    "Word embeddings, on the other hand, refer more broadly to the idea of mapping words or phrases to vectors of numbers. There are other algorithms besides Word2Vec that can be used to learn word embeddings, and word embeddings can also be pre-trained and then fine-tuned on a specific task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8a2272be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine: ['of', 'computer', 'to', 'subfield', 'is', 'field', 'science', 'another', 'deep', 'a']\n",
      "learning: ['of', 'science', 'processing', 'language', 'is', 'vision', 'related', 'machine', 'subfield', 'field']\n",
      "is: ['of', 'related', 'machine', 'science', 'another', 'field', 'computer', 'a', 'learning', 'language']\n",
      "a: ['of', 'natural', 'field', 'another', 'machine', 'subfield', 'is', 'to', 'vision', 'related']\n",
      "field: ['processing', 'machine', 'to', 'of', 'a', 'is', 'deep', 'another', 'natural', 'related']\n",
      "of: ['a', 'subfield', 'science', 'machine', 'is', 'learning', 'another', 'field', 'computer', 'deep']\n",
      "computer: ['deep', 'science', 'machine', 'subfield', 'another', 'processing', 'is', 'of', 'language', 'field']\n",
      "science: ['language', 'of', 'computer', 'processing', 'another', 'machine', 'is', 'learning', 'vision', 'deep']\n",
      "deep: ['computer', 'to', 'processing', 'machine', 'language', 'natural', 'related', 'field', 'of', 'science']\n",
      "subfield: ['related', 'of', 'natural', 'vision', 'computer', 'machine', 'to', 'language', 'a', 'another']\n",
      "vision: ['related', 'subfield', 'to', 'processing', 'language', 'learning', 'another', 'of', 'science', 'a']\n",
      "related: ['subfield', 'language', 'vision', 'to', 'is', 'deep', 'natural', 'another', 'learning', 'field']\n",
      "to: ['related', 'deep', 'machine', 'vision', 'field', 'natural', 'subfield', 'a', 'language', 'learning']\n",
      "natural: ['subfield', 'language', 'another', 'a', 'to', 'processing', 'deep', 'related', 'field', 'of']\n",
      "language: ['related', 'science', 'natural', 'processing', 'subfield', 'another', 'deep', 'learning', 'vision', 'computer']\n",
      "processing: ['language', 'science', 'deep', 'field', 'another', 'natural', 'vision', 'computer', 'learning', 'of']\n",
      "another: ['science', 'natural', 'processing', 'of', 'is', 'machine', 'language', 'computer', 'a', 'field']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\PC\\anaconda3\\lib\\site-packages\\gensim\\models\\base_any2vec.py:742: UserWarning: C extension not loaded, training will be slow. Install a C compiler and reinstall gensim for fast training.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## use case 1ï¼š Topic modeling and text summarization\n",
    "\n",
    "# gensim is a pretrained word2vec model\n",
    "\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "\n",
    "# Load in the text data that you want to use for topic recognition\n",
    "text_data = [\n",
    "    \"machine learning is a field of computer science\",\n",
    "    \"deep learning is a subfield of machine learning\",\n",
    "    \"computer vision is a field related to machine learning\",\n",
    "    \"natural language processing is another field related to machine learning\"\n",
    "]\n",
    "\n",
    "# Preprocess the text data to remove punctuation, lowercase all words, etc.\n",
    "processed_text = [text.lower().split() for text in text_data]\n",
    "\n",
    "# Train the Word2Vec model on the processed text data\n",
    "model = Word2Vec(processed_text, size=100, window=5, min_count=1, workers=4)\n",
    "\n",
    "# Get the word vectors for each word in the vocabulary\n",
    "word_vectors = model.wv\n",
    "\n",
    "# Use the word vectors to perform topic recognition\n",
    "word_topics = {}\n",
    "for word in word_vectors.vocab:\n",
    "    most_similar_words = word_vectors.most_similar(word)\n",
    "    topics = [word for word, similarity in most_similar_words]\n",
    "    word_topics[word] = topics\n",
    "\n",
    "# Print the topics for each word\n",
    "for word, topics in word_topics.items():\n",
    "    print(f\"{word}: {topics}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f6176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
